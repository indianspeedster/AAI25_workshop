{
  "best_metric": 0.2633204162120819,
  "best_model_checkpoint": "qwen2-7b-instruct-trl-sft-ChartQA/checkpoint-240",
  "epoch": 2.937853107344633,
  "eval_steps": 10,
  "global_step": 260,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011299435028248588,
      "grad_norm": 5.880954265594482,
      "learning_rate": 0.0002,
      "loss": 2.9449,
      "step": 1
    },
    {
      "epoch": 0.022598870056497175,
      "grad_norm": 5.57641077041626,
      "learning_rate": 0.0002,
      "loss": 2.9127,
      "step": 2
    },
    {
      "epoch": 0.03389830508474576,
      "grad_norm": 6.081974029541016,
      "learning_rate": 0.0002,
      "loss": 2.8909,
      "step": 3
    },
    {
      "epoch": 0.04519774011299435,
      "grad_norm": 6.644047260284424,
      "learning_rate": 0.0002,
      "loss": 2.8123,
      "step": 4
    },
    {
      "epoch": 0.05649717514124294,
      "grad_norm": 7.006442070007324,
      "learning_rate": 0.0002,
      "loss": 2.6897,
      "step": 5
    },
    {
      "epoch": 0.06779661016949153,
      "grad_norm": 7.291884899139404,
      "learning_rate": 0.0002,
      "loss": 2.5909,
      "step": 6
    },
    {
      "epoch": 0.07909604519774012,
      "grad_norm": 7.397341728210449,
      "learning_rate": 0.0002,
      "loss": 2.5338,
      "step": 7
    },
    {
      "epoch": 0.0903954802259887,
      "grad_norm": 7.652833461761475,
      "learning_rate": 0.0002,
      "loss": 2.445,
      "step": 8
    },
    {
      "epoch": 0.1016949152542373,
      "grad_norm": 7.839783191680908,
      "learning_rate": 0.0002,
      "loss": 2.3279,
      "step": 9
    },
    {
      "epoch": 0.11299435028248588,
      "grad_norm": 8.342763900756836,
      "learning_rate": 0.0002,
      "loss": 2.2478,
      "step": 10
    },
    {
      "epoch": 0.11299435028248588,
      "eval_loss": 2.1381938457489014,
      "eval_runtime": 13.7825,
      "eval_samples_per_second": 13.931,
      "eval_steps_per_second": 3.483,
      "step": 10
    },
    {
      "epoch": 0.12429378531073447,
      "grad_norm": 9.038674354553223,
      "learning_rate": 0.0002,
      "loss": 2.147,
      "step": 11
    },
    {
      "epoch": 0.13559322033898305,
      "grad_norm": 9.327797889709473,
      "learning_rate": 0.0002,
      "loss": 2.0593,
      "step": 12
    },
    {
      "epoch": 0.14689265536723164,
      "grad_norm": 10.090980529785156,
      "learning_rate": 0.0002,
      "loss": 1.9616,
      "step": 13
    },
    {
      "epoch": 0.15819209039548024,
      "grad_norm": 10.726959228515625,
      "learning_rate": 0.0002,
      "loss": 1.8145,
      "step": 14
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 10.825857162475586,
      "learning_rate": 0.0002,
      "loss": 1.7183,
      "step": 15
    },
    {
      "epoch": 0.1807909604519774,
      "grad_norm": 11.557854652404785,
      "learning_rate": 0.0002,
      "loss": 1.6066,
      "step": 16
    },
    {
      "epoch": 0.192090395480226,
      "grad_norm": 11.84821605682373,
      "learning_rate": 0.0002,
      "loss": 1.5018,
      "step": 17
    },
    {
      "epoch": 0.2033898305084746,
      "grad_norm": 12.888887405395508,
      "learning_rate": 0.0002,
      "loss": 1.4047,
      "step": 18
    },
    {
      "epoch": 0.21468926553672316,
      "grad_norm": 13.139103889465332,
      "learning_rate": 0.0002,
      "loss": 1.2772,
      "step": 19
    },
    {
      "epoch": 0.22598870056497175,
      "grad_norm": 14.001468658447266,
      "learning_rate": 0.0002,
      "loss": 1.1793,
      "step": 20
    },
    {
      "epoch": 0.22598870056497175,
      "eval_loss": 1.0554593801498413,
      "eval_runtime": 13.6366,
      "eval_samples_per_second": 14.08,
      "eval_steps_per_second": 3.52,
      "step": 20
    },
    {
      "epoch": 0.23728813559322035,
      "grad_norm": 14.34266471862793,
      "learning_rate": 0.0002,
      "loss": 1.0908,
      "step": 21
    },
    {
      "epoch": 0.24858757062146894,
      "grad_norm": 17.19681739807129,
      "learning_rate": 0.0002,
      "loss": 0.9594,
      "step": 22
    },
    {
      "epoch": 0.2598870056497175,
      "grad_norm": 20.810428619384766,
      "learning_rate": 0.0002,
      "loss": 0.9159,
      "step": 23
    },
    {
      "epoch": 0.2711864406779661,
      "grad_norm": 19.576553344726562,
      "learning_rate": 0.0002,
      "loss": 0.7866,
      "step": 24
    },
    {
      "epoch": 0.2824858757062147,
      "grad_norm": 21.347135543823242,
      "learning_rate": 0.0002,
      "loss": 0.6905,
      "step": 25
    },
    {
      "epoch": 0.2937853107344633,
      "grad_norm": 16.52678680419922,
      "learning_rate": 0.0002,
      "loss": 0.5835,
      "step": 26
    },
    {
      "epoch": 0.3050847457627119,
      "grad_norm": 11.222212791442871,
      "learning_rate": 0.0002,
      "loss": 0.5509,
      "step": 27
    },
    {
      "epoch": 0.3163841807909605,
      "grad_norm": 6.17711877822876,
      "learning_rate": 0.0002,
      "loss": 0.477,
      "step": 28
    },
    {
      "epoch": 0.327683615819209,
      "grad_norm": 3.660036087036133,
      "learning_rate": 0.0002,
      "loss": 0.4784,
      "step": 29
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 2.4207446575164795,
      "learning_rate": 0.0002,
      "loss": 0.4893,
      "step": 30
    },
    {
      "epoch": 0.3389830508474576,
      "eval_loss": 0.43405914306640625,
      "eval_runtime": 14.0734,
      "eval_samples_per_second": 13.643,
      "eval_steps_per_second": 3.411,
      "step": 30
    },
    {
      "epoch": 0.3502824858757062,
      "grad_norm": 2.0759308338165283,
      "learning_rate": 0.0002,
      "loss": 0.4555,
      "step": 31
    },
    {
      "epoch": 0.3615819209039548,
      "grad_norm": 2.5961711406707764,
      "learning_rate": 0.0002,
      "loss": 0.5018,
      "step": 32
    },
    {
      "epoch": 0.3728813559322034,
      "grad_norm": 1.8050528764724731,
      "learning_rate": 0.0002,
      "loss": 0.4415,
      "step": 33
    },
    {
      "epoch": 0.384180790960452,
      "grad_norm": 1.7401313781738281,
      "learning_rate": 0.0002,
      "loss": 0.4794,
      "step": 34
    },
    {
      "epoch": 0.3954802259887006,
      "grad_norm": 1.812622308731079,
      "learning_rate": 0.0002,
      "loss": 0.4489,
      "step": 35
    },
    {
      "epoch": 0.4067796610169492,
      "grad_norm": 2.020254135131836,
      "learning_rate": 0.0002,
      "loss": 0.4621,
      "step": 36
    },
    {
      "epoch": 0.4180790960451977,
      "grad_norm": 2.0066628456115723,
      "learning_rate": 0.0002,
      "loss": 0.4778,
      "step": 37
    },
    {
      "epoch": 0.4293785310734463,
      "grad_norm": 1.7325977087020874,
      "learning_rate": 0.0002,
      "loss": 0.4404,
      "step": 38
    },
    {
      "epoch": 0.4406779661016949,
      "grad_norm": 1.8636854887008667,
      "learning_rate": 0.0002,
      "loss": 0.4089,
      "step": 39
    },
    {
      "epoch": 0.4519774011299435,
      "grad_norm": 1.7304625511169434,
      "learning_rate": 0.0002,
      "loss": 0.4087,
      "step": 40
    },
    {
      "epoch": 0.4519774011299435,
      "eval_loss": 0.4001961648464203,
      "eval_runtime": 13.5678,
      "eval_samples_per_second": 14.151,
      "eval_steps_per_second": 3.538,
      "step": 40
    },
    {
      "epoch": 0.4632768361581921,
      "grad_norm": 2.0586531162261963,
      "learning_rate": 0.0002,
      "loss": 0.4424,
      "step": 41
    },
    {
      "epoch": 0.4745762711864407,
      "grad_norm": 2.130925178527832,
      "learning_rate": 0.0002,
      "loss": 0.4086,
      "step": 42
    },
    {
      "epoch": 0.4858757062146893,
      "grad_norm": 2.2943098545074463,
      "learning_rate": 0.0002,
      "loss": 0.437,
      "step": 43
    },
    {
      "epoch": 0.4971751412429379,
      "grad_norm": 2.4366390705108643,
      "learning_rate": 0.0002,
      "loss": 0.4291,
      "step": 44
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 3.208832025527954,
      "learning_rate": 0.0002,
      "loss": 0.401,
      "step": 45
    },
    {
      "epoch": 0.519774011299435,
      "grad_norm": 7.792361736297607,
      "learning_rate": 0.0002,
      "loss": 0.4092,
      "step": 46
    },
    {
      "epoch": 0.5310734463276836,
      "grad_norm": 10.68800163269043,
      "learning_rate": 0.0002,
      "loss": 0.4147,
      "step": 47
    },
    {
      "epoch": 0.5423728813559322,
      "grad_norm": 12.403417587280273,
      "learning_rate": 0.0002,
      "loss": 0.3975,
      "step": 48
    },
    {
      "epoch": 0.5536723163841808,
      "grad_norm": 11.724699974060059,
      "learning_rate": 0.0002,
      "loss": 0.3758,
      "step": 49
    },
    {
      "epoch": 0.5649717514124294,
      "grad_norm": 9.64476203918457,
      "learning_rate": 0.0002,
      "loss": 0.3628,
      "step": 50
    },
    {
      "epoch": 0.5649717514124294,
      "eval_loss": 0.3340650498867035,
      "eval_runtime": 13.5872,
      "eval_samples_per_second": 14.131,
      "eval_steps_per_second": 3.533,
      "step": 50
    },
    {
      "epoch": 0.576271186440678,
      "grad_norm": 8.136396408081055,
      "learning_rate": 0.0002,
      "loss": 0.3444,
      "step": 51
    },
    {
      "epoch": 0.5875706214689266,
      "grad_norm": 7.680008888244629,
      "learning_rate": 0.0002,
      "loss": 0.3516,
      "step": 52
    },
    {
      "epoch": 0.5988700564971752,
      "grad_norm": 6.713037967681885,
      "learning_rate": 0.0002,
      "loss": 0.3616,
      "step": 53
    },
    {
      "epoch": 0.6101694915254238,
      "grad_norm": 3.4386990070343018,
      "learning_rate": 0.0002,
      "loss": 0.3282,
      "step": 54
    },
    {
      "epoch": 0.6214689265536724,
      "grad_norm": 2.6685078144073486,
      "learning_rate": 0.0002,
      "loss": 0.3294,
      "step": 55
    },
    {
      "epoch": 0.632768361581921,
      "grad_norm": 2.365595817565918,
      "learning_rate": 0.0002,
      "loss": 0.3379,
      "step": 56
    },
    {
      "epoch": 0.6440677966101694,
      "grad_norm": 1.9457426071166992,
      "learning_rate": 0.0002,
      "loss": 0.3162,
      "step": 57
    },
    {
      "epoch": 0.655367231638418,
      "grad_norm": 1.8433693647384644,
      "learning_rate": 0.0002,
      "loss": 0.3276,
      "step": 58
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.3966788053512573,
      "learning_rate": 0.0002,
      "loss": 0.3326,
      "step": 59
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 1.6409335136413574,
      "learning_rate": 0.0002,
      "loss": 0.324,
      "step": 60
    },
    {
      "epoch": 0.6779661016949152,
      "eval_loss": 0.2952839136123657,
      "eval_runtime": 14.1593,
      "eval_samples_per_second": 13.56,
      "eval_steps_per_second": 3.39,
      "step": 60
    },
    {
      "epoch": 0.6892655367231638,
      "grad_norm": 1.3014576435089111,
      "learning_rate": 0.0002,
      "loss": 0.3142,
      "step": 61
    },
    {
      "epoch": 0.7005649717514124,
      "grad_norm": 1.6438955068588257,
      "learning_rate": 0.0002,
      "loss": 0.2792,
      "step": 62
    },
    {
      "epoch": 0.711864406779661,
      "grad_norm": 1.4514539241790771,
      "learning_rate": 0.0002,
      "loss": 0.3548,
      "step": 63
    },
    {
      "epoch": 0.7231638418079096,
      "grad_norm": 1.8300203084945679,
      "learning_rate": 0.0002,
      "loss": 0.3013,
      "step": 64
    },
    {
      "epoch": 0.7344632768361582,
      "grad_norm": 1.3374062776565552,
      "learning_rate": 0.0002,
      "loss": 0.294,
      "step": 65
    },
    {
      "epoch": 0.7457627118644068,
      "grad_norm": 1.4366682767868042,
      "learning_rate": 0.0002,
      "loss": 0.3157,
      "step": 66
    },
    {
      "epoch": 0.7570621468926554,
      "grad_norm": 1.532301425933838,
      "learning_rate": 0.0002,
      "loss": 0.2874,
      "step": 67
    },
    {
      "epoch": 0.768361581920904,
      "grad_norm": 1.4268718957901,
      "learning_rate": 0.0002,
      "loss": 0.3048,
      "step": 68
    },
    {
      "epoch": 0.7796610169491526,
      "grad_norm": 3.1564581394195557,
      "learning_rate": 0.0002,
      "loss": 0.3193,
      "step": 69
    },
    {
      "epoch": 0.7909604519774012,
      "grad_norm": 1.8204498291015625,
      "learning_rate": 0.0002,
      "loss": 0.3212,
      "step": 70
    },
    {
      "epoch": 0.7909604519774012,
      "eval_loss": 0.29088354110717773,
      "eval_runtime": 13.5721,
      "eval_samples_per_second": 14.147,
      "eval_steps_per_second": 3.537,
      "step": 70
    },
    {
      "epoch": 0.8022598870056498,
      "grad_norm": 1.568115234375,
      "learning_rate": 0.0002,
      "loss": 0.313,
      "step": 71
    },
    {
      "epoch": 0.8135593220338984,
      "grad_norm": 1.5295037031173706,
      "learning_rate": 0.0002,
      "loss": 0.3189,
      "step": 72
    },
    {
      "epoch": 0.8248587570621468,
      "grad_norm": 1.54448401927948,
      "learning_rate": 0.0002,
      "loss": 0.3046,
      "step": 73
    },
    {
      "epoch": 0.8361581920903954,
      "grad_norm": 1.5484575033187866,
      "learning_rate": 0.0002,
      "loss": 0.3459,
      "step": 74
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 1.714778184890747,
      "learning_rate": 0.0002,
      "loss": 0.3128,
      "step": 75
    },
    {
      "epoch": 0.8587570621468926,
      "grad_norm": 1.3110859394073486,
      "learning_rate": 0.0002,
      "loss": 0.3081,
      "step": 76
    },
    {
      "epoch": 0.8700564971751412,
      "grad_norm": 1.822464108467102,
      "learning_rate": 0.0002,
      "loss": 0.3347,
      "step": 77
    },
    {
      "epoch": 0.8813559322033898,
      "grad_norm": 1.4326390027999878,
      "learning_rate": 0.0002,
      "loss": 0.3388,
      "step": 78
    },
    {
      "epoch": 0.8926553672316384,
      "grad_norm": 1.6710753440856934,
      "learning_rate": 0.0002,
      "loss": 0.3319,
      "step": 79
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 1.3844784498214722,
      "learning_rate": 0.0002,
      "loss": 0.2977,
      "step": 80
    },
    {
      "epoch": 0.903954802259887,
      "eval_loss": 0.2884986400604248,
      "eval_runtime": 13.8846,
      "eval_samples_per_second": 13.828,
      "eval_steps_per_second": 3.457,
      "step": 80
    },
    {
      "epoch": 0.9152542372881356,
      "grad_norm": 1.5801973342895508,
      "learning_rate": 0.0002,
      "loss": 0.3008,
      "step": 81
    },
    {
      "epoch": 0.9265536723163842,
      "grad_norm": 1.4206019639968872,
      "learning_rate": 0.0002,
      "loss": 0.2962,
      "step": 82
    },
    {
      "epoch": 0.9378531073446328,
      "grad_norm": 1.3151885271072388,
      "learning_rate": 0.0002,
      "loss": 0.3116,
      "step": 83
    },
    {
      "epoch": 0.9491525423728814,
      "grad_norm": 1.4733784198760986,
      "learning_rate": 0.0002,
      "loss": 0.2908,
      "step": 84
    },
    {
      "epoch": 0.96045197740113,
      "grad_norm": 1.3830115795135498,
      "learning_rate": 0.0002,
      "loss": 0.3125,
      "step": 85
    },
    {
      "epoch": 0.9717514124293786,
      "grad_norm": 1.4440891742706299,
      "learning_rate": 0.0002,
      "loss": 0.3214,
      "step": 86
    },
    {
      "epoch": 0.9830508474576272,
      "grad_norm": 1.4786629676818848,
      "learning_rate": 0.0002,
      "loss": 0.3326,
      "step": 87
    },
    {
      "epoch": 0.9943502824858758,
      "grad_norm": 1.2024791240692139,
      "learning_rate": 0.0002,
      "loss": 0.296,
      "step": 88
    },
    {
      "epoch": 1.0056497175141244,
      "grad_norm": 1.2225362062454224,
      "learning_rate": 0.0002,
      "loss": 0.2939,
      "step": 89
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 1.0948909521102905,
      "learning_rate": 0.0002,
      "loss": 0.2894,
      "step": 90
    },
    {
      "epoch": 1.0169491525423728,
      "eval_loss": 0.28353169560432434,
      "eval_runtime": 13.4488,
      "eval_samples_per_second": 14.276,
      "eval_steps_per_second": 3.569,
      "step": 90
    },
    {
      "epoch": 1.0282485875706215,
      "grad_norm": 1.2880187034606934,
      "learning_rate": 0.0002,
      "loss": 0.3176,
      "step": 91
    },
    {
      "epoch": 1.03954802259887,
      "grad_norm": 1.1853824853897095,
      "learning_rate": 0.0002,
      "loss": 0.3098,
      "step": 92
    },
    {
      "epoch": 1.0508474576271187,
      "grad_norm": 1.2791452407836914,
      "learning_rate": 0.0002,
      "loss": 0.3043,
      "step": 93
    },
    {
      "epoch": 1.0621468926553672,
      "grad_norm": 1.1961150169372559,
      "learning_rate": 0.0002,
      "loss": 0.2691,
      "step": 94
    },
    {
      "epoch": 1.073446327683616,
      "grad_norm": 1.308379054069519,
      "learning_rate": 0.0002,
      "loss": 0.3063,
      "step": 95
    },
    {
      "epoch": 1.0847457627118644,
      "grad_norm": 1.81635582447052,
      "learning_rate": 0.0002,
      "loss": 0.3192,
      "step": 96
    },
    {
      "epoch": 1.0960451977401129,
      "grad_norm": 1.386643648147583,
      "learning_rate": 0.0002,
      "loss": 0.3108,
      "step": 97
    },
    {
      "epoch": 1.1073446327683616,
      "grad_norm": 1.2397667169570923,
      "learning_rate": 0.0002,
      "loss": 0.2972,
      "step": 98
    },
    {
      "epoch": 1.11864406779661,
      "grad_norm": 1.2748332023620605,
      "learning_rate": 0.0002,
      "loss": 0.2857,
      "step": 99
    },
    {
      "epoch": 1.1299435028248588,
      "grad_norm": 1.181579351425171,
      "learning_rate": 0.0002,
      "loss": 0.3021,
      "step": 100
    },
    {
      "epoch": 1.1299435028248588,
      "eval_loss": 0.28094854950904846,
      "eval_runtime": 14.029,
      "eval_samples_per_second": 13.686,
      "eval_steps_per_second": 3.421,
      "step": 100
    },
    {
      "epoch": 1.1412429378531073,
      "grad_norm": 1.3349355459213257,
      "learning_rate": 0.0002,
      "loss": 0.3054,
      "step": 101
    },
    {
      "epoch": 1.152542372881356,
      "grad_norm": 1.4538344144821167,
      "learning_rate": 0.0002,
      "loss": 0.27,
      "step": 102
    },
    {
      "epoch": 1.1638418079096045,
      "grad_norm": 1.0662261247634888,
      "learning_rate": 0.0002,
      "loss": 0.269,
      "step": 103
    },
    {
      "epoch": 1.1751412429378532,
      "grad_norm": 1.092625379562378,
      "learning_rate": 0.0002,
      "loss": 0.284,
      "step": 104
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 1.376394271850586,
      "learning_rate": 0.0002,
      "loss": 0.31,
      "step": 105
    },
    {
      "epoch": 1.1977401129943503,
      "grad_norm": 1.2409167289733887,
      "learning_rate": 0.0002,
      "loss": 0.2865,
      "step": 106
    },
    {
      "epoch": 1.2090395480225988,
      "grad_norm": 1.253084659576416,
      "learning_rate": 0.0002,
      "loss": 0.3143,
      "step": 107
    },
    {
      "epoch": 1.2203389830508475,
      "grad_norm": 1.2826100587844849,
      "learning_rate": 0.0002,
      "loss": 0.2933,
      "step": 108
    },
    {
      "epoch": 1.231638418079096,
      "grad_norm": 1.2461048364639282,
      "learning_rate": 0.0002,
      "loss": 0.2961,
      "step": 109
    },
    {
      "epoch": 1.2429378531073447,
      "grad_norm": 1.37306547164917,
      "learning_rate": 0.0002,
      "loss": 0.2793,
      "step": 110
    },
    {
      "epoch": 1.2429378531073447,
      "eval_loss": 0.2799232602119446,
      "eval_runtime": 13.4574,
      "eval_samples_per_second": 14.267,
      "eval_steps_per_second": 3.567,
      "step": 110
    },
    {
      "epoch": 1.2542372881355932,
      "grad_norm": 1.556166410446167,
      "learning_rate": 0.0002,
      "loss": 0.3259,
      "step": 111
    },
    {
      "epoch": 1.2655367231638417,
      "grad_norm": 1.3033113479614258,
      "learning_rate": 0.0002,
      "loss": 0.2729,
      "step": 112
    },
    {
      "epoch": 1.2768361581920904,
      "grad_norm": 1.2634522914886475,
      "learning_rate": 0.0002,
      "loss": 0.2881,
      "step": 113
    },
    {
      "epoch": 1.288135593220339,
      "grad_norm": 1.5558888912200928,
      "learning_rate": 0.0002,
      "loss": 0.3124,
      "step": 114
    },
    {
      "epoch": 1.2994350282485876,
      "grad_norm": 1.3670179843902588,
      "learning_rate": 0.0002,
      "loss": 0.2875,
      "step": 115
    },
    {
      "epoch": 1.310734463276836,
      "grad_norm": 1.4019601345062256,
      "learning_rate": 0.0002,
      "loss": 0.3056,
      "step": 116
    },
    {
      "epoch": 1.3220338983050848,
      "grad_norm": 1.4013084173202515,
      "learning_rate": 0.0002,
      "loss": 0.3163,
      "step": 117
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.2387218475341797,
      "learning_rate": 0.0002,
      "loss": 0.2971,
      "step": 118
    },
    {
      "epoch": 1.344632768361582,
      "grad_norm": 1.2654061317443848,
      "learning_rate": 0.0002,
      "loss": 0.281,
      "step": 119
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 1.275058627128601,
      "learning_rate": 0.0002,
      "loss": 0.2742,
      "step": 120
    },
    {
      "epoch": 1.3559322033898304,
      "eval_loss": 0.27652353048324585,
      "eval_runtime": 13.2302,
      "eval_samples_per_second": 14.512,
      "eval_steps_per_second": 3.628,
      "step": 120
    },
    {
      "epoch": 1.3672316384180792,
      "grad_norm": 1.2003449201583862,
      "learning_rate": 0.0002,
      "loss": 0.2606,
      "step": 121
    },
    {
      "epoch": 1.3785310734463276,
      "grad_norm": 1.3388910293579102,
      "learning_rate": 0.0002,
      "loss": 0.2969,
      "step": 122
    },
    {
      "epoch": 1.3898305084745763,
      "grad_norm": 1.615594744682312,
      "learning_rate": 0.0002,
      "loss": 0.3001,
      "step": 123
    },
    {
      "epoch": 1.4011299435028248,
      "grad_norm": 1.343982219696045,
      "learning_rate": 0.0002,
      "loss": 0.3027,
      "step": 124
    },
    {
      "epoch": 1.4124293785310735,
      "grad_norm": 1.2344287633895874,
      "learning_rate": 0.0002,
      "loss": 0.2974,
      "step": 125
    },
    {
      "epoch": 1.423728813559322,
      "grad_norm": 1.168912649154663,
      "learning_rate": 0.0002,
      "loss": 0.271,
      "step": 126
    },
    {
      "epoch": 1.4350282485875705,
      "grad_norm": 1.2290021181106567,
      "learning_rate": 0.0002,
      "loss": 0.2615,
      "step": 127
    },
    {
      "epoch": 1.4463276836158192,
      "grad_norm": 1.1658177375793457,
      "learning_rate": 0.0002,
      "loss": 0.302,
      "step": 128
    },
    {
      "epoch": 1.457627118644068,
      "grad_norm": 1.4383606910705566,
      "learning_rate": 0.0002,
      "loss": 0.2842,
      "step": 129
    },
    {
      "epoch": 1.4689265536723164,
      "grad_norm": 1.169134259223938,
      "learning_rate": 0.0002,
      "loss": 0.2927,
      "step": 130
    },
    {
      "epoch": 1.4689265536723164,
      "eval_loss": 0.27591386437416077,
      "eval_runtime": 13.1714,
      "eval_samples_per_second": 14.577,
      "eval_steps_per_second": 3.644,
      "step": 130
    },
    {
      "epoch": 1.4802259887005649,
      "grad_norm": 1.3466209173202515,
      "learning_rate": 0.0002,
      "loss": 0.3044,
      "step": 131
    },
    {
      "epoch": 1.4915254237288136,
      "grad_norm": 1.4106779098510742,
      "learning_rate": 0.0002,
      "loss": 0.2769,
      "step": 132
    },
    {
      "epoch": 1.5028248587570623,
      "grad_norm": 1.405411958694458,
      "learning_rate": 0.0002,
      "loss": 0.2828,
      "step": 133
    },
    {
      "epoch": 1.5141242937853108,
      "grad_norm": 1.3119702339172363,
      "learning_rate": 0.0002,
      "loss": 0.2841,
      "step": 134
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 1.5062038898468018,
      "learning_rate": 0.0002,
      "loss": 0.3202,
      "step": 135
    },
    {
      "epoch": 1.536723163841808,
      "grad_norm": 1.367661714553833,
      "learning_rate": 0.0002,
      "loss": 0.3122,
      "step": 136
    },
    {
      "epoch": 1.5480225988700564,
      "grad_norm": 1.4419310092926025,
      "learning_rate": 0.0002,
      "loss": 0.3103,
      "step": 137
    },
    {
      "epoch": 1.559322033898305,
      "grad_norm": 1.4894957542419434,
      "learning_rate": 0.0002,
      "loss": 0.2849,
      "step": 138
    },
    {
      "epoch": 1.5706214689265536,
      "grad_norm": 1.5623619556427002,
      "learning_rate": 0.0002,
      "loss": 0.2763,
      "step": 139
    },
    {
      "epoch": 1.5819209039548023,
      "grad_norm": 1.7026426792144775,
      "learning_rate": 0.0002,
      "loss": 0.2889,
      "step": 140
    },
    {
      "epoch": 1.5819209039548023,
      "eval_loss": 0.2726301848888397,
      "eval_runtime": 13.3935,
      "eval_samples_per_second": 14.335,
      "eval_steps_per_second": 3.584,
      "step": 140
    },
    {
      "epoch": 1.5932203389830508,
      "grad_norm": 1.6195305585861206,
      "learning_rate": 0.0002,
      "loss": 0.3172,
      "step": 141
    },
    {
      "epoch": 1.6045197740112993,
      "grad_norm": 1.351914882659912,
      "learning_rate": 0.0002,
      "loss": 0.2873,
      "step": 142
    },
    {
      "epoch": 1.615819209039548,
      "grad_norm": 1.6109087467193604,
      "learning_rate": 0.0002,
      "loss": 0.2845,
      "step": 143
    },
    {
      "epoch": 1.6271186440677967,
      "grad_norm": 1.5129344463348389,
      "learning_rate": 0.0002,
      "loss": 0.2909,
      "step": 144
    },
    {
      "epoch": 1.6384180790960452,
      "grad_norm": 1.2912380695343018,
      "learning_rate": 0.0002,
      "loss": 0.2731,
      "step": 145
    },
    {
      "epoch": 1.6497175141242937,
      "grad_norm": 1.3921337127685547,
      "learning_rate": 0.0002,
      "loss": 0.2917,
      "step": 146
    },
    {
      "epoch": 1.6610169491525424,
      "grad_norm": 1.542897343635559,
      "learning_rate": 0.0002,
      "loss": 0.2935,
      "step": 147
    },
    {
      "epoch": 1.672316384180791,
      "grad_norm": 1.6595455408096313,
      "learning_rate": 0.0002,
      "loss": 0.2862,
      "step": 148
    },
    {
      "epoch": 1.6836158192090396,
      "grad_norm": 1.451210379600525,
      "learning_rate": 0.0002,
      "loss": 0.2887,
      "step": 149
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 1.8868257999420166,
      "learning_rate": 0.0002,
      "loss": 0.278,
      "step": 150
    },
    {
      "epoch": 1.694915254237288,
      "eval_loss": 0.27223193645477295,
      "eval_runtime": 13.1429,
      "eval_samples_per_second": 14.609,
      "eval_steps_per_second": 3.652,
      "step": 150
    },
    {
      "epoch": 1.7062146892655368,
      "grad_norm": 1.5897043943405151,
      "learning_rate": 0.0002,
      "loss": 0.2826,
      "step": 151
    },
    {
      "epoch": 1.7175141242937855,
      "grad_norm": 1.91861093044281,
      "learning_rate": 0.0002,
      "loss": 0.2945,
      "step": 152
    },
    {
      "epoch": 1.7288135593220337,
      "grad_norm": 1.4574133157730103,
      "learning_rate": 0.0002,
      "loss": 0.2807,
      "step": 153
    },
    {
      "epoch": 1.7401129943502824,
      "grad_norm": 1.5175893306732178,
      "learning_rate": 0.0002,
      "loss": 0.2924,
      "step": 154
    },
    {
      "epoch": 1.7514124293785311,
      "grad_norm": 1.4931602478027344,
      "learning_rate": 0.0002,
      "loss": 0.284,
      "step": 155
    },
    {
      "epoch": 1.7627118644067796,
      "grad_norm": 1.4425901174545288,
      "learning_rate": 0.0002,
      "loss": 0.3046,
      "step": 156
    },
    {
      "epoch": 1.774011299435028,
      "grad_norm": 1.48521089553833,
      "learning_rate": 0.0002,
      "loss": 0.2869,
      "step": 157
    },
    {
      "epoch": 1.7853107344632768,
      "grad_norm": 1.464476227760315,
      "learning_rate": 0.0002,
      "loss": 0.2933,
      "step": 158
    },
    {
      "epoch": 1.7966101694915255,
      "grad_norm": 1.443084716796875,
      "learning_rate": 0.0002,
      "loss": 0.2909,
      "step": 159
    },
    {
      "epoch": 1.807909604519774,
      "grad_norm": 1.4356549978256226,
      "learning_rate": 0.0002,
      "loss": 0.2879,
      "step": 160
    },
    {
      "epoch": 1.807909604519774,
      "eval_loss": 0.27009105682373047,
      "eval_runtime": 13.6959,
      "eval_samples_per_second": 14.019,
      "eval_steps_per_second": 3.505,
      "step": 160
    },
    {
      "epoch": 1.8192090395480225,
      "grad_norm": 1.5238127708435059,
      "learning_rate": 0.0002,
      "loss": 0.3038,
      "step": 161
    },
    {
      "epoch": 1.8305084745762712,
      "grad_norm": 1.5838302373886108,
      "learning_rate": 0.0002,
      "loss": 0.2923,
      "step": 162
    },
    {
      "epoch": 1.84180790960452,
      "grad_norm": 1.464884638786316,
      "learning_rate": 0.0002,
      "loss": 0.2778,
      "step": 163
    },
    {
      "epoch": 1.8531073446327684,
      "grad_norm": 1.5098963975906372,
      "learning_rate": 0.0002,
      "loss": 0.2696,
      "step": 164
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 1.7618310451507568,
      "learning_rate": 0.0002,
      "loss": 0.2712,
      "step": 165
    },
    {
      "epoch": 1.8757062146892656,
      "grad_norm": 1.472621202468872,
      "learning_rate": 0.0002,
      "loss": 0.2829,
      "step": 166
    },
    {
      "epoch": 1.8870056497175143,
      "grad_norm": 1.4033912420272827,
      "learning_rate": 0.0002,
      "loss": 0.2514,
      "step": 167
    },
    {
      "epoch": 1.8983050847457628,
      "grad_norm": 1.3948050737380981,
      "learning_rate": 0.0002,
      "loss": 0.2667,
      "step": 168
    },
    {
      "epoch": 1.9096045197740112,
      "grad_norm": 1.7023428678512573,
      "learning_rate": 0.0002,
      "loss": 0.2726,
      "step": 169
    },
    {
      "epoch": 1.92090395480226,
      "grad_norm": 1.6907758712768555,
      "learning_rate": 0.0002,
      "loss": 0.282,
      "step": 170
    },
    {
      "epoch": 1.92090395480226,
      "eval_loss": 0.26863035559654236,
      "eval_runtime": 13.2361,
      "eval_samples_per_second": 14.506,
      "eval_steps_per_second": 3.626,
      "step": 170
    },
    {
      "epoch": 1.9322033898305084,
      "grad_norm": 1.6102182865142822,
      "learning_rate": 0.0002,
      "loss": 0.3031,
      "step": 171
    },
    {
      "epoch": 1.943502824858757,
      "grad_norm": 1.7896720170974731,
      "learning_rate": 0.0002,
      "loss": 0.2799,
      "step": 172
    },
    {
      "epoch": 1.9548022598870056,
      "grad_norm": 1.4289860725402832,
      "learning_rate": 0.0002,
      "loss": 0.2651,
      "step": 173
    },
    {
      "epoch": 1.9661016949152543,
      "grad_norm": 1.5285269021987915,
      "learning_rate": 0.0002,
      "loss": 0.325,
      "step": 174
    },
    {
      "epoch": 1.9774011299435028,
      "grad_norm": 1.3719230890274048,
      "learning_rate": 0.0002,
      "loss": 0.2801,
      "step": 175
    },
    {
      "epoch": 1.9887005649717513,
      "grad_norm": 1.414137601852417,
      "learning_rate": 0.0002,
      "loss": 0.2852,
      "step": 176
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.5341912508010864,
      "learning_rate": 0.0002,
      "loss": 0.2747,
      "step": 177
    },
    {
      "epoch": 2.0112994350282487,
      "grad_norm": 1.5623959302902222,
      "learning_rate": 0.0002,
      "loss": 0.2972,
      "step": 178
    },
    {
      "epoch": 2.022598870056497,
      "grad_norm": 1.495705246925354,
      "learning_rate": 0.0002,
      "loss": 0.2749,
      "step": 179
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 1.414696455001831,
      "learning_rate": 0.0002,
      "loss": 0.267,
      "step": 180
    },
    {
      "epoch": 2.0338983050847457,
      "eval_loss": 0.2681143581867218,
      "eval_runtime": 13.2845,
      "eval_samples_per_second": 14.453,
      "eval_steps_per_second": 3.613,
      "step": 180
    },
    {
      "epoch": 2.0451977401129944,
      "grad_norm": 1.2878162860870361,
      "learning_rate": 0.0002,
      "loss": 0.2892,
      "step": 181
    },
    {
      "epoch": 2.056497175141243,
      "grad_norm": 1.3900495767593384,
      "learning_rate": 0.0002,
      "loss": 0.3055,
      "step": 182
    },
    {
      "epoch": 2.0677966101694913,
      "grad_norm": 1.5841952562332153,
      "learning_rate": 0.0002,
      "loss": 0.2762,
      "step": 183
    },
    {
      "epoch": 2.07909604519774,
      "grad_norm": 1.6625217199325562,
      "learning_rate": 0.0002,
      "loss": 0.2831,
      "step": 184
    },
    {
      "epoch": 2.0903954802259888,
      "grad_norm": 1.6159172058105469,
      "learning_rate": 0.0002,
      "loss": 0.2787,
      "step": 185
    },
    {
      "epoch": 2.1016949152542375,
      "grad_norm": 1.5171536207199097,
      "learning_rate": 0.0002,
      "loss": 0.267,
      "step": 186
    },
    {
      "epoch": 2.1129943502824857,
      "grad_norm": 1.6373331546783447,
      "learning_rate": 0.0002,
      "loss": 0.2962,
      "step": 187
    },
    {
      "epoch": 2.1242937853107344,
      "grad_norm": 1.735194206237793,
      "learning_rate": 0.0002,
      "loss": 0.2885,
      "step": 188
    },
    {
      "epoch": 2.135593220338983,
      "grad_norm": 1.6868242025375366,
      "learning_rate": 0.0002,
      "loss": 0.2949,
      "step": 189
    },
    {
      "epoch": 2.146892655367232,
      "grad_norm": 1.4609228372573853,
      "learning_rate": 0.0002,
      "loss": 0.2667,
      "step": 190
    },
    {
      "epoch": 2.146892655367232,
      "eval_loss": 0.2666141390800476,
      "eval_runtime": 13.5551,
      "eval_samples_per_second": 14.164,
      "eval_steps_per_second": 3.541,
      "step": 190
    },
    {
      "epoch": 2.15819209039548,
      "grad_norm": 1.6725773811340332,
      "learning_rate": 0.0002,
      "loss": 0.2661,
      "step": 191
    },
    {
      "epoch": 2.169491525423729,
      "grad_norm": 1.6101701259613037,
      "learning_rate": 0.0002,
      "loss": 0.2638,
      "step": 192
    },
    {
      "epoch": 2.1807909604519775,
      "grad_norm": 1.4416277408599854,
      "learning_rate": 0.0002,
      "loss": 0.2749,
      "step": 193
    },
    {
      "epoch": 2.1920903954802258,
      "grad_norm": 1.5131771564483643,
      "learning_rate": 0.0002,
      "loss": 0.2685,
      "step": 194
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 1.3898484706878662,
      "learning_rate": 0.0002,
      "loss": 0.2492,
      "step": 195
    },
    {
      "epoch": 2.214689265536723,
      "grad_norm": 1.4067879915237427,
      "learning_rate": 0.0002,
      "loss": 0.2647,
      "step": 196
    },
    {
      "epoch": 2.225988700564972,
      "grad_norm": 1.8106881380081177,
      "learning_rate": 0.0002,
      "loss": 0.2836,
      "step": 197
    },
    {
      "epoch": 2.23728813559322,
      "grad_norm": 1.8184396028518677,
      "learning_rate": 0.0002,
      "loss": 0.304,
      "step": 198
    },
    {
      "epoch": 2.248587570621469,
      "grad_norm": 1.4512330293655396,
      "learning_rate": 0.0002,
      "loss": 0.2784,
      "step": 199
    },
    {
      "epoch": 2.2598870056497176,
      "grad_norm": 1.7043060064315796,
      "learning_rate": 0.0002,
      "loss": 0.2989,
      "step": 200
    },
    {
      "epoch": 2.2598870056497176,
      "eval_loss": 0.26710155606269836,
      "eval_runtime": 13.7513,
      "eval_samples_per_second": 13.962,
      "eval_steps_per_second": 3.491,
      "step": 200
    },
    {
      "epoch": 2.2711864406779663,
      "grad_norm": 1.460292100906372,
      "learning_rate": 0.0002,
      "loss": 0.2817,
      "step": 201
    },
    {
      "epoch": 2.2824858757062145,
      "grad_norm": 1.8347524404525757,
      "learning_rate": 0.0002,
      "loss": 0.3003,
      "step": 202
    },
    {
      "epoch": 2.2937853107344632,
      "grad_norm": 1.640833854675293,
      "learning_rate": 0.0002,
      "loss": 0.2754,
      "step": 203
    },
    {
      "epoch": 2.305084745762712,
      "grad_norm": 1.6568470001220703,
      "learning_rate": 0.0002,
      "loss": 0.2568,
      "step": 204
    },
    {
      "epoch": 2.3163841807909606,
      "grad_norm": 1.636844277381897,
      "learning_rate": 0.0002,
      "loss": 0.2905,
      "step": 205
    },
    {
      "epoch": 2.327683615819209,
      "grad_norm": 1.69186270236969,
      "learning_rate": 0.0002,
      "loss": 0.2496,
      "step": 206
    },
    {
      "epoch": 2.3389830508474576,
      "grad_norm": 1.5423076152801514,
      "learning_rate": 0.0002,
      "loss": 0.2485,
      "step": 207
    },
    {
      "epoch": 2.3502824858757063,
      "grad_norm": 1.7168740034103394,
      "learning_rate": 0.0002,
      "loss": 0.277,
      "step": 208
    },
    {
      "epoch": 2.361581920903955,
      "grad_norm": 1.7629872560501099,
      "learning_rate": 0.0002,
      "loss": 0.276,
      "step": 209
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 1.953816294670105,
      "learning_rate": 0.0002,
      "loss": 0.2957,
      "step": 210
    },
    {
      "epoch": 2.3728813559322033,
      "eval_loss": 0.2671559154987335,
      "eval_runtime": 13.853,
      "eval_samples_per_second": 13.86,
      "eval_steps_per_second": 3.465,
      "step": 210
    },
    {
      "epoch": 2.384180790960452,
      "grad_norm": 1.7913230657577515,
      "learning_rate": 0.0002,
      "loss": 0.2757,
      "step": 211
    },
    {
      "epoch": 2.3954802259887007,
      "grad_norm": 1.5914300680160522,
      "learning_rate": 0.0002,
      "loss": 0.2565,
      "step": 212
    },
    {
      "epoch": 2.406779661016949,
      "grad_norm": 1.5255931615829468,
      "learning_rate": 0.0002,
      "loss": 0.2458,
      "step": 213
    },
    {
      "epoch": 2.4180790960451977,
      "grad_norm": 1.7351213693618774,
      "learning_rate": 0.0002,
      "loss": 0.2829,
      "step": 214
    },
    {
      "epoch": 2.4293785310734464,
      "grad_norm": 1.6332509517669678,
      "learning_rate": 0.0002,
      "loss": 0.2706,
      "step": 215
    },
    {
      "epoch": 2.440677966101695,
      "grad_norm": 1.6376146078109741,
      "learning_rate": 0.0002,
      "loss": 0.2786,
      "step": 216
    },
    {
      "epoch": 2.4519774011299433,
      "grad_norm": 1.5394721031188965,
      "learning_rate": 0.0002,
      "loss": 0.265,
      "step": 217
    },
    {
      "epoch": 2.463276836158192,
      "grad_norm": 1.5582213401794434,
      "learning_rate": 0.0002,
      "loss": 0.2787,
      "step": 218
    },
    {
      "epoch": 2.4745762711864407,
      "grad_norm": 1.6711726188659668,
      "learning_rate": 0.0002,
      "loss": 0.2754,
      "step": 219
    },
    {
      "epoch": 2.4858757062146895,
      "grad_norm": 1.497275948524475,
      "learning_rate": 0.0002,
      "loss": 0.2677,
      "step": 220
    },
    {
      "epoch": 2.4858757062146895,
      "eval_loss": 0.266184002161026,
      "eval_runtime": 13.8532,
      "eval_samples_per_second": 13.86,
      "eval_steps_per_second": 3.465,
      "step": 220
    },
    {
      "epoch": 2.4971751412429377,
      "grad_norm": 1.7888907194137573,
      "learning_rate": 0.0002,
      "loss": 0.2828,
      "step": 221
    },
    {
      "epoch": 2.5084745762711864,
      "grad_norm": 1.5754101276397705,
      "learning_rate": 0.0002,
      "loss": 0.2735,
      "step": 222
    },
    {
      "epoch": 2.519774011299435,
      "grad_norm": 1.6423828601837158,
      "learning_rate": 0.0002,
      "loss": 0.2515,
      "step": 223
    },
    {
      "epoch": 2.5310734463276834,
      "grad_norm": 1.6406214237213135,
      "learning_rate": 0.0002,
      "loss": 0.2624,
      "step": 224
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 2.0899860858917236,
      "learning_rate": 0.0002,
      "loss": 0.303,
      "step": 225
    },
    {
      "epoch": 2.553672316384181,
      "grad_norm": 1.7851675748825073,
      "learning_rate": 0.0002,
      "loss": 0.2542,
      "step": 226
    },
    {
      "epoch": 2.5649717514124295,
      "grad_norm": 1.9131771326065063,
      "learning_rate": 0.0002,
      "loss": 0.2884,
      "step": 227
    },
    {
      "epoch": 2.576271186440678,
      "grad_norm": 1.5920652151107788,
      "learning_rate": 0.0002,
      "loss": 0.2375,
      "step": 228
    },
    {
      "epoch": 2.5875706214689265,
      "grad_norm": 1.7323672771453857,
      "learning_rate": 0.0002,
      "loss": 0.2709,
      "step": 229
    },
    {
      "epoch": 2.598870056497175,
      "grad_norm": 1.8541197776794434,
      "learning_rate": 0.0002,
      "loss": 0.2568,
      "step": 230
    },
    {
      "epoch": 2.598870056497175,
      "eval_loss": 0.2654106914997101,
      "eval_runtime": 13.9373,
      "eval_samples_per_second": 13.776,
      "eval_steps_per_second": 3.444,
      "step": 230
    },
    {
      "epoch": 2.610169491525424,
      "grad_norm": 1.720144510269165,
      "learning_rate": 0.0002,
      "loss": 0.2725,
      "step": 231
    },
    {
      "epoch": 2.621468926553672,
      "grad_norm": 1.7012466192245483,
      "learning_rate": 0.0002,
      "loss": 0.2473,
      "step": 232
    },
    {
      "epoch": 2.632768361581921,
      "grad_norm": 1.6172257661819458,
      "learning_rate": 0.0002,
      "loss": 0.2608,
      "step": 233
    },
    {
      "epoch": 2.6440677966101696,
      "grad_norm": 1.6549874544143677,
      "learning_rate": 0.0002,
      "loss": 0.2619,
      "step": 234
    },
    {
      "epoch": 2.655367231638418,
      "grad_norm": 1.7656943798065186,
      "learning_rate": 0.0002,
      "loss": 0.2579,
      "step": 235
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 2.185136556625366,
      "learning_rate": 0.0002,
      "loss": 0.2865,
      "step": 236
    },
    {
      "epoch": 2.6779661016949152,
      "grad_norm": 1.7249358892440796,
      "learning_rate": 0.0002,
      "loss": 0.2682,
      "step": 237
    },
    {
      "epoch": 2.689265536723164,
      "grad_norm": 1.7155450582504272,
      "learning_rate": 0.0002,
      "loss": 0.2705,
      "step": 238
    },
    {
      "epoch": 2.7005649717514126,
      "grad_norm": 1.5658915042877197,
      "learning_rate": 0.0002,
      "loss": 0.2788,
      "step": 239
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 1.6640660762786865,
      "learning_rate": 0.0002,
      "loss": 0.28,
      "step": 240
    },
    {
      "epoch": 2.711864406779661,
      "eval_loss": 0.2633204162120819,
      "eval_runtime": 13.7099,
      "eval_samples_per_second": 14.005,
      "eval_steps_per_second": 3.501,
      "step": 240
    },
    {
      "epoch": 2.7231638418079096,
      "grad_norm": 1.7550421953201294,
      "learning_rate": 0.0002,
      "loss": 0.2675,
      "step": 241
    },
    {
      "epoch": 2.7344632768361583,
      "grad_norm": 1.5526988506317139,
      "learning_rate": 0.0002,
      "loss": 0.2484,
      "step": 242
    },
    {
      "epoch": 2.7457627118644066,
      "grad_norm": 1.6891164779663086,
      "learning_rate": 0.0002,
      "loss": 0.2615,
      "step": 243
    },
    {
      "epoch": 2.7570621468926553,
      "grad_norm": 1.6679370403289795,
      "learning_rate": 0.0002,
      "loss": 0.2568,
      "step": 244
    },
    {
      "epoch": 2.768361581920904,
      "grad_norm": 1.803398609161377,
      "learning_rate": 0.0002,
      "loss": 0.2632,
      "step": 245
    },
    {
      "epoch": 2.7796610169491527,
      "grad_norm": 1.678396463394165,
      "learning_rate": 0.0002,
      "loss": 0.2538,
      "step": 246
    },
    {
      "epoch": 2.7909604519774014,
      "grad_norm": 1.7658072710037231,
      "learning_rate": 0.0002,
      "loss": 0.2595,
      "step": 247
    },
    {
      "epoch": 2.8022598870056497,
      "grad_norm": 2.1240506172180176,
      "learning_rate": 0.0002,
      "loss": 0.2947,
      "step": 248
    },
    {
      "epoch": 2.8135593220338984,
      "grad_norm": 1.944717526435852,
      "learning_rate": 0.0002,
      "loss": 0.2529,
      "step": 249
    },
    {
      "epoch": 2.824858757062147,
      "grad_norm": 2.078204393386841,
      "learning_rate": 0.0002,
      "loss": 0.2602,
      "step": 250
    },
    {
      "epoch": 2.824858757062147,
      "eval_loss": 0.2647491991519928,
      "eval_runtime": 13.316,
      "eval_samples_per_second": 14.419,
      "eval_steps_per_second": 3.605,
      "step": 250
    },
    {
      "epoch": 2.8361581920903953,
      "grad_norm": 1.7504308223724365,
      "learning_rate": 0.0002,
      "loss": 0.2369,
      "step": 251
    },
    {
      "epoch": 2.847457627118644,
      "grad_norm": 2.0339677333831787,
      "learning_rate": 0.0002,
      "loss": 0.2826,
      "step": 252
    },
    {
      "epoch": 2.8587570621468927,
      "grad_norm": 1.8822588920593262,
      "learning_rate": 0.0002,
      "loss": 0.2661,
      "step": 253
    },
    {
      "epoch": 2.870056497175141,
      "grad_norm": 1.578688383102417,
      "learning_rate": 0.0002,
      "loss": 0.2495,
      "step": 254
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 1.8501156568527222,
      "learning_rate": 0.0002,
      "loss": 0.2723,
      "step": 255
    },
    {
      "epoch": 2.8926553672316384,
      "grad_norm": 1.8946677446365356,
      "learning_rate": 0.0002,
      "loss": 0.2914,
      "step": 256
    },
    {
      "epoch": 2.903954802259887,
      "grad_norm": 1.8786747455596924,
      "learning_rate": 0.0002,
      "loss": 0.2783,
      "step": 257
    },
    {
      "epoch": 2.915254237288136,
      "grad_norm": 1.58579683303833,
      "learning_rate": 0.0002,
      "loss": 0.2713,
      "step": 258
    },
    {
      "epoch": 2.926553672316384,
      "grad_norm": 1.9096349477767944,
      "learning_rate": 0.0002,
      "loss": 0.267,
      "step": 259
    },
    {
      "epoch": 2.937853107344633,
      "grad_norm": 1.5460602045059204,
      "learning_rate": 0.0002,
      "loss": 0.2522,
      "step": 260
    },
    {
      "epoch": 2.937853107344633,
      "eval_loss": 0.2640596628189087,
      "eval_runtime": 14.068,
      "eval_samples_per_second": 13.648,
      "eval_steps_per_second": 3.412,
      "step": 260
    }
  ],
  "logging_steps": 1,
  "max_steps": 264,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1528388967008256e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
